{"activation": "relu", "alpha": 0.1, "hidden_layer_sizes": [200]}